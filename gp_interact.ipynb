{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gaussian process regression: Introduction\n",
    "\n",
    "Let's generate some fake, one dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ndim = 10\n",
    "\n",
    "x = np.arange(ndim)[:, np.newaxis]\n",
    "y = np.arange(ndim)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "y = np.random.rand(ndim)[:, None]\n",
    "y -= y.mean()\n",
    "x = np.arange(len(y))[:, None]\n",
    "yerr = y.std() / 2 * np.ones_like(x)\n",
    "\n",
    "plt.errorbar(x, y, yerr, fmt='.', color='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Linear regression\n",
    "\n",
    "Solutions to the [ordinary least squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) estimators $\\hat{\\beta}$ are\n",
    "\n",
    "$$ \\hat{\\beta} = ({\\bf X}^\\top {\\bf N}^{-1} {\\bf X})^{-1} {\\bf X}^\\top {\\bf N}^{-1} y,$$\n",
    "\n",
    "and their uncertainties are given by\n",
    "\n",
    "$$ \\mathrm{cov} = {\\bf X}^\\top {\\bf N}^{-1} {\\bf X}, $$\n",
    "\n",
    "where ${\\bf N}$ is the matrix of uncertainties on measurements $y$ (${\\bf N}$ is diagonal for measurements with independent Gaussian uncertainties, in this case). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Append a column of ones next to the `x` values using `np.vander`: \n",
    "X = np.vander(x.ravel(), 2)\n",
    "inv_N = np.linalg.inv(np.identity(len(x)) * yerr**2)\n",
    "\n",
    "# Solve linear regression: \n",
    "betas = np.linalg.inv(X.T @ inv_N @ X) @ X.T @ inv_N @ y\n",
    "cov = np.linalg.inv(X.T @ inv_N @ X)\n",
    "\n",
    "# Compute best fit line: \n",
    "best_fit = X @ betas \n",
    "err = np.sqrt(np.diag(cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Plot the result and its uncertainty (here we're plotting just the uncertainty in the intercept and ignoring the uncertainty in the slope, for this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.errorbar(x, y, yerr, fmt='.', color='k')\n",
    "plt.plot(x, best_fit)\n",
    "plt.fill_between(x.ravel(), best_fit.ravel()-err[1], best_fit.ravel()+err[1], alpha=0.3)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gaussian process regression\n",
    "\n",
    "From [Rasmussen and Williams (2006)](http://www.gaussianprocess.org/gpml/), the predicted mean is going to be (Equation 2.25) \n",
    "\n",
    "$$ \\mu = {\\bf k_*}^\\top ({\\bf K} + \\sigma_n {\\bf I})^{-1} {\\bf y},  $$\n",
    "\n",
    "and the covariance is going to be (Equation 2.26)\n",
    "\n",
    "$$ \\mathrm{cov} = k({\\bf x_*}, {\\bf x_*})- {\\bf k_*}^\\top ({\\bf K }+ \\sigma_n {\\bf I})^{-1} {\\bf k_*}, $$ \n",
    "\n",
    "and therefore the error on the predictions will be\n",
    "\n",
    "$$ \\mathrm{err} = \\mathrm{diag}\\left( \\sqrt{\\mathrm{cov}} \\right).$$\n",
    "\n",
    "Define a \"squared exponential\" (Gaussian) kernel function\n",
    "\n",
    "$$ K({\\bf x_1}, {\\bf x_2}) = \\sigma^2 \\exp\\left(-\\frac{(x_1 - x_2)^2)}{2 \\ell^2}\\right)   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def square_distance(x1, x2): \n",
    "    \"\"\"\n",
    "    Compute the squared distance between two vectors `x1` and `x2` \n",
    "    \"\"\"\n",
    "    return np.sum(x1**2, axis=1)[:, np.newaxis] + np.sum(x2**2, axis=1) - 2 * np.dot(x1, x2.T)\n",
    "\n",
    "def sq_exp_kernel(x1, x2, sigma=1, ell=1): \n",
    "    \"\"\"\n",
    "    Gaussian Kernel function\n",
    "    \"\"\"\n",
    "    sqdist = square_distance(x1, x2)\n",
    "\n",
    "    return sigma**2 * np.exp(-0.5 * sqdist / ell**2)\n",
    "\n",
    "def gaussian_process_regression(x, y, yerr, xtest, kernel): \n",
    "    \"\"\"\n",
    "    Gaussian process regression for column vectors `x` and `y` with \n",
    "    uncertainties `yerr`; predict values at `xtest` using `kernel`\n",
    "    \"\"\"\n",
    "    K = kernel(x, x) + np.identity(len(x)) * yerr**2\n",
    "    k_s = kernel(x, xtest)\n",
    "    k_ss = kernel(xtest, xtest)\n",
    "    inv_K = np.linalg.inv(K)\n",
    "    mu = k_s.T @ inv_K @ y\n",
    "    cov = k_ss - k_s.T @ inv_K @ k_s\n",
    "    return mu, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "xtest = np.linspace(x.min(), x.max(), N)[:, np.newaxis]\n",
    "\n",
    "mu, cov = gaussian_process_regression(x, y, yerr, xtest, sq_exp_kernel)\n",
    "\n",
    "err = np.sqrt(np.diagonal(cov))\n",
    "\n",
    "plt.errorbar(x, y, yerr, fmt='.', color='k')\n",
    "plt.plot(xtest.ravel(), mu.ravel(), label='GP mean')\n",
    "plt.fill_between(xtest.ravel(), mu.ravel()-err, mu.ravel()+err, alpha=0.3, label='GP uncertainty')\n",
    "plt.legend(loc='upper center')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Make an interactive plot\n",
    "\n",
    "which allows you to vary the $\\ell$ hyperparameter and see the results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gp_interact(ell):\n",
    "    def sq_exp_kernel_interactive(x1, x2, sigma=1, ell=ell): \n",
    "        \"\"\"\n",
    "        Interactive Gaussian Kernel function\n",
    "        \"\"\"\n",
    "        sqdist = np.sum(x1**2, axis=1)[:, np.newaxis] + np.sum(x2**2, axis=1) - 2 * np.dot(x1, x2.T)\n",
    "\n",
    "        return sigma**2 * np.exp(-0.5 * sqdist / ell**2)\n",
    "    \n",
    "    mu, cov = gaussian_process_regression(x, y, yerr, xtest, sq_exp_kernel_interactive)\n",
    "    err = np.sqrt(np.diag(cov))\n",
    "\n",
    "    plt.errorbar(x, y, yerr, fmt='.', color='k')\n",
    "    plt.plot(xtest.ravel(), mu.ravel())\n",
    "    plt.fill_between(xtest.ravel(),  mu.ravel()-err, mu.ravel()+err, alpha=0.2)\n",
    "    plt.gca().set(xlabel='x', ylabel='y')\n",
    "    plt.show()\n",
    "\n",
    "print('Vary the hyperparameter \"ell\", which defines the autocorrelation timescale:')\n",
    "interactive_plot = interactive(gp_interact, ell=(1, 10, 1))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
